version: "3"

services:
  mongodb:
    image: mongo
    volumes:
      - mongo_db:/data/db
    ports:
      - 27017:27017
    networks:
      - crawler_app
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.key == db

  rabbitmq:
    image: rabbitmq:3.9-management
    environment:
      - RABBITMQ_DEFAULT_USER=crawler
      - RABBITMQ_DEFAULT_PASS=123456789
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq/
      - rabbitmq_log:/var/log/rabbitmq
    ports:
      - 5672:5672
      - 15672:15672
    networks:
      - crawler_app
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.key == db 

  crawler:
    image: seeker00837149/crawler
    environment:
      - MONGO=mongodb
      - MONGO_PORT=27017
      - RMQ_HOST=rabbitmq
      - RMQ_QUEUE=crawler
      - RMQ_USERNAME=crawler
      - RMQ_PASSWORD=123456789
      - CHECK_INTERVAL=20
      - EXCLUDE_URLS=.*github.com
    ports:
      - 8000:8000
    networks:
      - crawler_app
    logging:
      driver: "fluentd"
      options:
        fluentd-async-connect: "true"
        tag: service.crawler
    deploy:
      mode: replicated      
      replicas: 3
      restart_policy:
        condition: on-failure

  ui:
    image: seeker00837149/web_ui
    environment:
      - MONGO=mongodb
      - MONGO_PORT=27017
    ports:
      - 80:8000
    networks:
      - crawler_app
    logging:
      driver: "fluentd"
      options:
        fluentd-async-connect: "true"
        tag: service.crawler_ui
    deploy:
      mode: replicated      
      replicas: 2 
      restart_policy:
        condition: on-failure

volumes:
  mongo_db:
  rabbitmq_data:
  rabbitmq_log:

networks:
  crawler_app:
    external:
      name: crawler_app
